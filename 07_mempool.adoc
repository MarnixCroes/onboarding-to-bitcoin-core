= Mempool

== Mempool terminology

Ancestor(s):: One or more "parent" transactions which must be confirmed **before** the current transaction. +
The ancestor transaction(s) _create_ outputs which are depended on by the current transaction.
Descendant(s):: One or more "child" transactions which must be confirmed **after** the current transaction. +
The descendant transaction(s) _depend_ on outputs from the current transaction.
Orphan:: A transaction with missing ancestors.

TIP: When _ancestor_ and _descendant_ are encountered in the codebase, they refer specifically to other **in-mempool** transactions.

TIP: Ancestors and descendants can be confirmed in the same block but they must be in the correct order within the list of `transactions` for the block to be valid.

== Mempool purpose

. The mempool is designed to hold a list of unconfirmed-but-valid transactions that the node has learned about.
. Miners will select transactions from the mempool for assembly into a block using the `getblocktemplate` RPC.
. Transactions have to pass all policy and validation checks before being allowed to enter the mempool. +
The mempool therefore also acts as DoS protection for the node.
. Transactions will not be added to the mempool if they do not meet fee requirements, are non-standard, or double-spend an input of a transaction already in the mempool (excluding BIP 125 RBF transactions).

There is a bitcoin-devwiki page https://github.com/bitcoin-core/bitcoin-devwiki/wiki/Mempool-and-mining[Mempool and mining^] which includes some additional mempool philosophy.

James O'Beirne has https://github.com/jamesob/mempool.work/blob/master/README.md[written] a comprehensive overview of the current challenges and work in mempool design.
It "documents the existing design, failures, and vulnerabilities of the mempool as well as some proposals that exist to remedy the shortcomings."

== Mempool policy goals

The documentation subfolder https://github.com/bitcoin/bitcoin/tree/master/doc/policy[doc/policy^] contains up-to-date information on **some**, but not all, of the current mempool policy rules.

== Mempool life cycle

=== Initialisation

The primary mempool object itself is initialized onto the `node` in _init.cpp_ as part of `AppInitMain()` which takes `NodeContext& node` as an argument.

.init.cpp#AppInitMain()
[source,cpp,options=nowrap]
----
assert(!node.mempool);
int check_ratio = std::min<int>(std::max<int>(args.GetIntArg("-checkmempool", chainparams.DefaultConsistencyChecks() ? 1 : 0), 0), 1000000);
node.mempool = std::make_unique<CTxMemPool>(node.fee_estimator.get(), check_ratio);
----

[NOTE]
====
The `check_ratio`, used to determine sanity checks, defaults to `0` for all networks except regtest, unless the `checkmempool` program option has been specified.

Sanity checking here refers to checking the consistency of the entire mempool every 1 in `n` times a new transaction is added, so is potentially computationally expensive to have enabled. +
See `CTxMemPool::Check()` for more information on what the check does.
====

==== Loading a previous mempool

If the node has been run before then it might have some blocks and a mempool to load.
"Step 11: import blocks" of `AppInitMain()` in _init.cpp_ calls `ThreadImport()` to load the mempool from disk where it is saved to file `mempool.dat`:

.init.cpp#AppInitMain()
[source,cpp,options=nowrap]
----
    chainman.m_load_block = std::thread(&TraceThread<std::function<void()>>, "loadblk", [=, &chainman, &args] {
        ThreadImport(chainman, vImportFiles, args);
    });
----

TIP: This is run in its own thread so that (potentially) slow disk I/O has a minimal impact on startup times, and the remainder of startup execution can be continued.

`ThreadImport` runs a few jobs sequentially:

. Optionally perform a reindex
. Load the block files from disk
. Check that we are still on the best chain according to the blocks loaded from disk
. Load the mempool via `chainman.ActiveChainstate().LoadMempool(args);`

`validation.cpp#LoadMempool()` is an almost mirror of `DumpMempool()` described in more detail below in <<Mempool shutdown>>:

. Read the version and count of serialized transactions to follow
. Test each tx for expiry before submitting it to MemPoolAccept
. Read any remaining `mapDeltas` and `unbroadcast_txids` from the file and apply them


[id=default_mempool_expire]
[TIP]
====
We test for expiry because it is current default policy not to keep transactions in the mempool longer than 336 hours, i.e. two weeks. +
The default value comes from the constant `DEFAULT_MEMPOOL_EXPIRE` which can be overridden by the user with the `-mempoolexpiry` option. +
Loading (and validating) a mempool of transactions this old is likely a waste of time and resources.
====

=== Runtime execution

While the node is running the mempool is persisted in memory.
By default the mempool is limited to 300MB as specified by `DEFAULT_MAX_MEMPOOL_SIZE`.
This can be overridden by the program option `maxmempoolsize`.

See <<Transaction format in the mempool>> for more information on what data counts towards this limit, or review the `CTxMemPool` data members which store current usage metrics e.g. `CTxMemPool::cachedInnerUsage` and the implementation of e.g. `CTxMemPool::DynamicMemoryUsage()`.

=== Mempool shutdown

When the node is shut down its mempool is (by default) persisted to disk, called from `init.cpp#Shutdown()`:

.init.cpp#Shutdown()
[source,cpp,options=nowrap]
----
    if (node.mempool && node.mempool->IsLoaded() && node.args->GetArg("-persistmempool", DEFAULT_PERSIST_MEMPOOL)) {
        DumpMempool(*node.mempool);
    }
----

A pointer to the mempool object is passed to `DumpMempool()`, which begins by locking the mempool mutex, `pool.cs`, before a snapshot of the mempool is created using local variables `mapDeltas`, `vinfo` and `unbroadcast_txids`.

TIP: `mapDeltas` is used by miners to apply (fee) prioritisation to certain transactions when creating new block templates.

TIP: `vinfo` stores information on each transaction as a vector of `CTxMemPoolInfo` objects.

.validation.cpp#DumpMempool()
[source,cpp,options=nowrap]
----
bool DumpMempool(const CTxMemPool& pool, FopenFn mockable_fopen_function, bool skip_file_commit)
{
    int64_t start = GetTimeMicros();

    std::map<uint256, CAmount> mapDeltas;
    std::vector<TxMempoolInfo> vinfo;
    std::set<uint256> unbroadcast_txids;

    static Mutex dump_mutex;
    LOCK(dump_mutex);

    {
        LOCK(pool.cs);
        for (const auto &i : pool.mapDeltas) {
            mapDeltas[i.first] = i.second;
        }
        vinfo = pool.infoAll();
        unbroadcast_txids = pool.GetUnbroadcastTxs();
    }
----

Next a new (temporary) file is opened and some metadata related to mempool version and size is written to the front.
Afterwards we loop through `vinfo` writing the transaction, the time it entered the mempool and the fee delta (prioritisation) to the file, before deleting its entry from our `mapDeltas` mirror.

Finally, any remaining info in `mapDeltas` is appended to the file.
This might include prioritisation information on transactions not in our mempool.

.validation.cpp#DumpMempool()
[source,cpp,options=nowrap]
----
    // ...
    try {
        FILE* filestr{mockable_fopen_function(GetDataDir() / "mempool.dat.new", "wb")};
        if (!filestr) {
            return false;
        }

        CAutoFile file(filestr, SER_DISK, CLIENT_VERSION);

        uint64_t version = MEMPOOL_DUMP_VERSION;
        file << version;

        file << (uint64_t)vinfo.size();
        for (const auto& i : vinfo) {
            file << *(i.tx);
            file << int64_t{count_seconds(i.m_time)};
            file << int64_t{i.nFeeDelta};
            mapDeltas.erase(i.tx->GetHash());
        }

        file << mapDeltas;

        LogPrintf("Writing %d unbroadcast transactions to disk.\n", unbroadcast_txids.size());
        file << unbroadcast_txids;
    // ...
}
----

****
We are able to write (and later read) `mapDeltas` and `unbroadcast_txids` to the file only using the `<<` operator.
This is due to the operator overload on the `CAutoFile` class found in _streams.h_:

.streams.h
[source,cpp,options=nowrap]
----
/**
 * map
 */
template<typename Stream, typename K, typename T, typename Pred, typename A>
void Serialize(Stream& os, const std::map<K, T, Pred, A>& m)
{
    WriteCompactSize(os, m.size());
    for (const auto& entry : m)
        Serialize(os, entry);
}

class: CAutoFile
{
public:
    // ...
    template<typename T>
    CAutoFile& operator<<(const T& obj)
    {
        // Serialize to this stream
        if (!file)
            throw std::ios_base::failure("CAutoFile::operator<<: file handle is nullptr");
        ::Serialize(*this, obj);
        return (*this);
    }
    // ...
};
----

****

Finally, if writing the elements to the temporary file was successful, we close the file and rename it to `mempool.dat`.

== Addition to the mempool

Transactions are added to the mempool via `addUnchecked()` as part of the `AcceptToMemoryPool()` flow.
See <<Transaction validation>> for more information on how this flow is entered.

WARNING: The function name `addUnchecked` specifically refers to the fact that no checks are being performed, so this must not be called until policy checks have passed.

This function is called from within _validation.cpp_ (`MemPoolAccept::Finalize()`) where the appropriate consensus and policy checks _have_ already been performed on the transaction.
The transaction is added to the primary index `mapTx` before any fee prioritisation ("delta") is applied to it.

Next any links to parent transactions are generated by looping through the inputs and mapping the `COutPoint` of the input to this transaction `CTransaction` in the `mapNextTx` map.
Additionally the tx input is added to a set which is used to update parent transactions if they are still in the mempool.

After all inputs have been considered, `UpdateAncestorsOf()` is called which will add this transaction as a descendant to any ancestors in the mempool.
This is followed by `UpdateEntryForAncestors()` which will re-calculate and apply descendant `count`, `size`, `fee` and `sigOpCost` of the ancestors with the new descendant being accounted for.

Finally update `totalTxSize` and `totalFee` (both sum totals of the mempool) to account for this new transaction.

////
Every entry in the mempool contains a transaction, metadata such as the time it was received, fees rates, optional block height and/or time needed to satisfy timelocks, and optional pointers to any ancestors and descendants in the mempool.

Much of the mempool is devoted to keeping track of a transaction's in-mempool ancestors and descendants and their aggregated fees.
A transaction is only valid if its ancestors exist, otherwise it is considered an orphan.
If a transaction is evicted from the mempool, its descendants must be too.

As such, a transaction's effective feerate is not just its base feerate divided by weight, but that of itself and all of its ancestors.
This information is also taken into account when the mempool fills up and the node must choose which transactions to evict (also based on fees).
Of course, all of this information can be calculated on the fly, but constructing a block is extremely time-sensitive, so the mempool opts to cache this information rather than spend more time calculating it.
As one might imagine, the family DAGs can get quite hairy and a source of resource exhaustion, so one part of mempool policy is to limit individual transactions' connectivity.

////

== Removal from the mempool

Transactions are removed from the mempool for a number of reasons:

. A new block has been connected `removeForBlock()`
. A re-org is taking place `removeForReorg()`
. The transaction has <<default_mempool_expire,expired>> `Expire()`
. The transaction is being replaced by a higher-fee version `MemPoolAccept::Finalize()`
. The mempool must be trimmed back down below its maximum size `TrimToSize()`

.Removal from the mempool
[mermaid,target=mempool-removal,format=svg,align="center"]
....
flowchart LR
    remove_staged["RemoveStaged()"]
    remove_recursive["removeRecursive()"]
    remove_reorg["removeForReorg()"]
    remove_block["removeForBlock()"]
    expire["Expire()"]
    trim_to_size["TrimToSize()"]
    finalize["MemPoolAccept::Finalize()"]
    calculate_ancestors["CalculateMemPoolAncestors()"]
    update_ancestors["UpdateAncestorsOf()"]
    update_children["UpdateChildrenForRemoval()"]
    remove_unchecked["removeUnchecked()"]
    
    remove_recursive --> remove_staged
    remove_reorg --> remove_staged
    remove_block --> remove_staged
    expire --> remove_staged
    trim_to_size --> remove_staged
    finalize ---> remove_staged
    
    remove_staged --> update_for_remove

    update_for_remove --> remove_unchecked
    
    subgraph validation.cpp
        finalize
    end
    
    subgraph txmempool.cpp
        remove_recursive
        remove_reorg
        remove_block
        expire
        trim_to_size
    end
    
    subgraph update_for_remove["UpdateForRemoveFromMempool()"]
        calculate_ancestors --> update_ancestors --> update_children
    end
....

`RemoveStaged()` takes a set of transactions referenced by their txid along with their https://github.com/bitcoin/bitcoin/blob/v23.0/src/txmempool.h#L347-L354[removal reason], and removes them sequentially.
It does this by first updating the ancestors of the transaction, followed by the descendants.
After calculating and updating related transaction information it calls `removeUnchecked()` which actions the removal from the mempool.

`removeUnchecked()` starts by notifying the validation interface that a transaction has been removed from the mempool for all reasons other than a new block arriving, as there is a different `BlockConnected` signal which can be used for that.

Next it loops over the ``txin``s of the transaction, and removes each `prevout` of each `txin` from the `mapNextTx` map.

[TIP]
====
`mapNextTx` is used to map a `COutPoint` to the unconfirmed transaction spending it.
This way there is a quick lookup available to check that a new transaction being added to the mempool is not trying to double spend a UTXO.

You can see the map being created as new transactions are learned about in https://github.com/bitcoin/bitcoin/blob/v23.0/src/txmempool.cpp#L510[`addUnchecked()`].
====

If the node has upgraded to SegWit the `vTxHashes` vector, which stores ``wtxid``s is then updated.
As `vTxHashes` stores the ``wtxid``s in random order, first we move the transaction's entry to the back, and then pop it off, resizing the vector if needed.

Finally, as with `addUnchecked()` we update the mempool sum totals for `txSize` and `fee` and erase the transaction from the primary mempool index `mapTx`.

TIP: Both adding and removing transactions increment the `mempool_seqence` counter.
This is used by the `getrawmempool` RPC (via `MempoolToJSON`) in tracking the number of mempool database transaction operations.

== Mempool unbroadcast set

The mempool contains an "unbroadcast" set called `m_unbroadcast_txids`.
As the name implies this stores the txids of transactions which are in our mempool but have not been verified as broadcast to the wider P2P network.
This might occur for example if a transaction is submitted locally (e.g. from the wallet or RPC), but we are not yet connected to any peers.

. When a transaction is submitted to the network via `BroadcastTransaction()` it is added to the unbroadcast set in the mempool, before `PeerManager` calls `RelayTransaction()` to attempt initial broadcast.
. When a transaction is heard about from the P2P network (via `getdata` in response to an `INV`), the transaction will be https://github.com/bitcoin/bitcoin/blob/v23.0/src/net_processing.cpp#L2022[removed] from the unbroadcast set.
+
TIP: Transactions are also removed from the set on reorgs, new blocks arriving or if they've "expired" via `RemoveStaged()`

`PeerManager` schedules `ReattemptInitialBroadcast()` to be run every 10 minutes.
This function loops over the unbroadcast set and either attempts rebroadcast or removes the transaction from the unbroadcast set if it is no longer in our mempool.

TIP: amiti wrote a https://gist.github.com/amitiuttarwar/b592ee410e1f02ac0d44fcbed4621dba[gist^] on her proposal to improve rebroadcast logic in Bitcoin Core.

== Transaction format in the mempool

A `CTXMemPoolEntry` describes a mempool entry (i.e. transaction) in the mempool.
It stores not only transaction information, but also pre-computed information about ancestors.

.txmempool.h
[source,cpp,options=nowrap]
----

class CTxMemPoolEntry
{
public:
    typedef std::reference_wrapper<const CTxMemPoolEntry> CTxMemPoolEntryRef;
    // two aliases, should the types ever diverge
    typedef std::set<CTxMemPoolEntryRef, CompareIteratorByHash> Parents;
    typedef std::set<CTxMemPoolEntryRef, CompareIteratorByHash> Children;

private:
    const CTransactionRef tx;
    mutable Parents m_parents;
    mutable Children m_children;
    const CAmount nFee;             //!< Cached to avoid expensive parent-transaction lookups
    const size_t nTxWeight;         //!< ... and avoid recomputing tx weight (also used for GetTxSize())
    const size_t nUsageSize;        //!< ... and total memory usage
    const int64_t nTime;            //!< Local time when entering the mempool
    const unsigned int entryHeight; //!< Chain height when entering the mempool
    const bool spendsCoinbase;      //!< keep track of transactions that spend a coinbase
    const int64_t sigOpCost;        //!< Total sigop cost
    int64_t feeDelta;          //!< Used for determining the priority of the transaction for mining in a block
    LockPoints lockPoints;     //!< Track the height and time at which tx was final

    // Information about descendants of this transaction that are in the
    // mempool; if we remove this transaction we must remove all of these
    // descendants as well.
    uint64_t nCountWithDescendants;  //!< number of descendant transactions
    uint64_t nSizeWithDescendants;   //!< ... and size
    CAmount nModFeesWithDescendants; //!< ... and total fees (all including us)

    // Analogous statistics for ancestor transactions
    uint64_t nCountWithAncestors;
    uint64_t nSizeWithAncestors;
    CAmount nModFeesWithAncestors;
    int64_t nSigOpCostWithAncestors;

    // ...
----

The advantage to having pre-computed data on descendants and ancestors stored with each transaction in the mempool is that operations involving adding and removing transactions can be performed faster.
When a transaction is added to the mempool we must update the descendant data for all ancestor ``CTxMemPoolEntry``'s.
Conversely if a transaction is removed from the mempool, we must also remove all of its descendants.
A particular area where speed can be critical is in block template assembly.

TIP: Some of this extra transaction metadata counts towards the mempool's maximum size, therefore a default mempool of 300MB will contain less than 300MB of serialized transactions.

== Mapping transactions in the mempool

A lot of how fee-maximizing block templates can be swiftly generated from chains of potentially-complex interlinked and dependant transactions comes down to ``CTxMemPool``'s `boost::multi_index` `mapTx`, which is able to natively store transactions in an index against multiple criteria as described in the https://www.boost.org/doc/libs/1_68_0/libs/multi_index/doc/index.html[documentation^] and code comments:

.txmempool.h#CTxMemPool
[source,cpp,options=nowrap]
----

/*
 * mapTx is a boost::multi_index that sorts the mempool on 5 criteria:
 * - transaction hash (txid)
 * - witness-transaction hash (wtxid)
 * - descendant feerate [we use max(feerate of tx, feerate of tx with all descendants)]
 * - time in mempool
 * - ancestor feerate [we use min(feerate of tx, feerate of tx with all unconfirmed ancestors)]
 */

----

The index has 5 sort fields: the default, and tagged fields `index_by_wtxid`, `descendant_score`, `entry_time` and `ancestor_score`:

. The default, and untagged, sort field of the index, which is using the https://www.boost.org/doc/libs/1_62_0/libs/multi_index/doc/reference/hash_indices.html#unique_non_unique[hashed_unique^] sort; hashing the `txid` using Bitcoin Core's implementation of the SipHash hasher for txids. +
This is used when adding and removing transactions from the mempool, requesting and looking up mempool transactions (by txid) and checking whether RBF is enabled.
. `index_by_wtxid` is used when checking whether transactions received over the P2P network already exist in the mempool (via the `exists()` function).
. `descendant_score` is used when trying to trim the mempool to size (via `TrimToSize()`). +
In this case we want to keep parent (ancestor) transactions in the mempool who have high fee-paying children (descendants).
. `entry_time` is used to calculate when transactions in the mempool should expire.
. `ancestor_score` is used to create new block templates by selecting the most valuable effective-feerate transaction chains.

== Package relay

https://bitcoinops.org/en/topics/package-relay/[Package Relay^] is a long-discussed concept and, at the time of writing, is a work in progress in Bitcoin Core.
A significant portion of the project involves changes to mempool validation, which glozow describes in her gist https://gist.github.com/glozow/dc4e9d5c5b14ade7cdfac40f43adb18a[Package mempool accept^].

https://github.com/bitcoin/bitcoin/pull/20833[PR#20833^] added the ability for mempool validation to assess a set of dependent transactions and enabled the `testmempoolaccept` RPC to support multiple transactions.

https://github.com/bitcoin/bitcoin/pull/21800[PR#21800^] added the ability to analyse and limit the ancestor and descendant sets of packages in relation to the mempool.

https://github.com/bitcoin/bitcoin/pull/22674[PR#22674^] defined child-with-unconfirmed-parents packages and enabled submission of such packages to the mempool.

These PRs were also accompanied by several refactoring efforts:
https://github.com/bitcoin/bitcoin/pull/21062[PR#21062^],
https://github.com/bitcoin/bitcoin/pull/22796[PR#22796^],
https://github.com/bitcoin/bitcoin/pull/22675[PR#22675^],
https://github.com/bitcoin/bitcoin/pull/22855[PR#22855^],
https://github.com/bitcoin/bitcoin/pull/23381[PR#23381^].

The document https://github.com/bitcoin/bitcoin/blob/master/doc/policy/packages.md[doc/policy/packages.md^] contains current information on the stated package acceptance rules.

== Pinning attacks

glozow describes pinning attacks in her document https://github.com/glozow/bitcoin-notes/blob/master/pinning.md["Pinning zoo"^].

////

== MemPoolAccept

The `MemPoolAccept` class handles mempool validation for new transactions.

Selecting the best transactions for the resource-constrained mempool involves a trade-off between optimistically validating candidates to identify the highest feerate ones and protecting the node from DoS attacks.
As such, we apply a set of validation rules known as mempool _policy_ in addition to consensus.

We can break down transaction validation checks into a few different classes:

* Consensus vs Policy: These can also be thought of as mandatory vs non-mandatory checks.
These two are not mutually exclusive, but we make efforts to compartmentalize consensus rules.
* Script vs Non-script: Script refers to the instructions and data used to specify and satisfy spending conditions.
We make this distinction because script checking (specifically, signature verification) is the most computationally intensive part of transaction validation.
* Contextual vs Context-Free: The context refers to our knowledge of the current state, represented as https://github.com/bitcoin/bitcoin/blob/v23.0/src/validation.h#L459[ChainState^].
Contextual checks might require the current block height or knowledge of the current UTXO set, while context-free checks only need the transaction itself.
We also need to look into our mempool to validate a transaction that spends unconfirmed parents or conflicts with another transaction already in our mempool.

=== Context-free non-script checks

Mempool validation in Bitcoin Core starts off with non-script checks (sometimes called https://github.com/bitcoin/bitcoin/blob/v23.0/src/validation.cpp#L668["PreChecks"^], the name of the function in which these checks run).

As a defensive strategy the node starts with context-free and/or easily computed checks.
Here are some examples:

* None of the outputs are trying to send a value https://github.com/bitcoin/bitcoin/blob/v23.0/src/consensus/tx_check.cpp#L26-L29[less than 0 or greater than 21 million BTC^].
* The transaction https://github.com/bitcoin/bitcoin/blob/v23.0/src/validation.cpp#L689-L691[isn't a coinbase^], as there can't be any coinbase transactions outside of blocks.
* The transaction isn't https://github.com/bitcoin/bitcoin/blob/v23.0/src/policy/policy.cpp#L93-L95[more than 400,000 weight units^].
+
It's possible for a larger transaction to be consensus-valid, but it would occupy too much space in the mempool.
If we allowed these transactions an attacker could try to dominate our mempool with very large transactions that are never mined.

=== Contextual non-script checks

Perhaps the most obvious non-script contextual check is to https://github.com/bitcoin/bitcoin/blob/v23.0/src/validation.cpp#L750-L771[make sure the inputs are available^], either in the current chainstate or an unspent output of an in-mempool transaction.
Instead of looking through the entire blockchain (hundreds of gigabytes stored on disk), Bitcoin Core nodes keep a https://github.com/bitcoin/bitcoin/blob/v23.0/src/validation.h#L410-L434[layered cache^] of the available https://github.com/bitcoin/bitcoin/blob/v23.0/src/coins.h#L30[coins^] which is a few gigabytes, much of which can be kept in memory.
To make this process more efficient, coins fetched from disk during mempool validation are https://github.com/bitcoin/bitcoin/blob/v23.0/src/validation.cpp#L1370-L1378[kept in memory^] if the transaction is accepted to the mempool.

Timelocks are also checked here - the node fetches the BIP113 Median Time Past and/or block height at the current chainstate to check transaction `nLockTime` and input `nSequence`

=== "Contextual" Script Checks

Transaction https://doxygen.bitcoincore.org/validation_8cpp.html#a6a96a3e1e6818904fdd5f51553b7ea60[script checks^] are actually context-free in isolation; the https://doxygen.bitcoincore.org/class_c_tx_in.html#aba540fd902366210a6ad6cd9a18fe763[`scriptSig`^] and https://github.com/bitcoin/bips/blob/master/bip-0141.mediawiki#specification[`witness`^] for each input, paired with the https://doxygen.bitcoincore.org/class_c_tx_out.html#a25bf3f2f4befb22a6a0be45784fe57e2[`scriptPubKey`^] in the https://github.com/bitcoin/bitcoin/blob/v23.0/src/validation.cpp#L1698[corresponding UTXO^] can be passed into the script interpreter and validated without state.
The https://doxygen.bitcoincore.org/interpreter_8h.html[script interpreter^] simply evaluates the series of opcodes and data based on the arguments passed to it.

The "context" passed to the script interpreter is a set of https://github.com/bitcoin/bitcoin/blob/v23.0/src/script/interpreter.h#L43-L147[script verification flags^] indicating which rules to apply during script verification.
For example, the `OP_CHECKSEQUENCEVERIFY` opcode repurposed `OP_NOP3`.
The script verification flag `SCRIPT_VERIFY_CHECKSEQUENCEVERIFY` instructs the script interpreter https://github.com/bitcoin/bitcoin/blob/v23.0/src/script/interpreter.cpp#L587[to interpret^] the opcode `0xb2` as the instruction to check that the input's `nSequence` is greater than the stack value or as a no-op. Starting at the BIP112 activation height, https://github.com/bitcoin/bitcoin/blob/v23.0/src/validation.cpp#L1893-L1896[nodes pass^] `SCRIPT_VERIFY_CHECKSEQUENCEVERIFY=1` into the script interpreter during consensus script checks.

=== Context-free Signature and Script Checks

Mempool validation performs two sets of script checks: https://github.com/bitcoin/bitcoin/blob/v23.0/src/validation.cpp#L973[`PolicyScriptChecks`^] and https://github.com/bitcoin/bitcoin/blob/v23.0/src/validation.cpp#L1001[`ConsensusScriptChecks`^].
The former runs the script interpreter using consensus and policy flags and caches the signature result (if successful) in the https://github.com/bitcoin/bitcoin/blob/v23.0/src/script/sigcache.cpp#L21-L26[signature cache^].
The latter runs the script interpreter using https://github.com/bitcoin/bitcoin/blob/v23.0/src/validation.cpp#L1025[consensus flags only^] and caches the full validation result in the script execution cache, identified by the wtxid and script verification flags.
If a new consensus rule is activated between now and the block in which this transaction is included, the cached result is no longer valid, but this is easily detected based on the script verification flags.

For example, before taproot rules are enforced in consensus, they are in policy (`SCRIPT_VERIFY_TAPROOT` included in policy but not consensus script verification flags); nodes won't relay and accept taproot-invalid version 1 transactions into their mempools, even though they aren't breaking any consensus rules yet.
All script checks will be cached without `SCRIPT_VERIFY_TAPROOT`.
After taproot activation, if a previously-validated transaction is seen, the cache entry's script verification flags won't match current consensus flags, so the node will re-run script checks for that transaction.

The most computationally-intensive part of script validation is signature verification (indicated in a script by opcodes such as `OP_CHECKSIG`), which doesn't change based on context.
To save the node from repetitive work, at the very start of script checks, parts of the transaction are https://github.com/bitcoin/bitcoin/blob/v23.0/src/script/interpreter.cpp#L1423[serialized, hashed, and stored^] in a `PrecomputedTransactionData` struct for use in signature verification.
This is especially handy in transactions that have multiple inputs and/or signatures.
Additionally, the cached result from `PolicyScriptChecks` can be used immediately in `ConsensusScriptChecks`; we almost never need to verify the same signature more than once!

////
